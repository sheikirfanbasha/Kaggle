{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure you are using right kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the initial set of training and test data. Do a quick analysis and train the model for least possible accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load the packages\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '/datasets/kaggle/competitions/home-credit-default-risk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir + \"/application_train.csv\", header=0, index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_dir + \"/application_test.csv\", header=0, index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few important notes when converting categorical values to numeric\n",
    "- Test dataset may not contain all the categories that are present in the training dataset\n",
    "- The categorical names to values map of training dataset shall match to that of test datasets (eg. if `cash loans` is mapped to `1`. It shall have the same value `1` in both test and train datasets\n",
    "\n",
    "*Note: In order to achieve the above. We shall merge the training and test datasets and then transform the categorical data to numeric ones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_temp = train.drop(['TARGET'], axis = 1)\n",
    "print(\"Train shape : {} \\n Test shape : {}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge_df = pd.concat([train_temp, test])\n",
    "print(merge_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find categorical columns\n",
    "categorical_cols = set(list(merge_df.columns)) - set(list(merge_df._get_numeric_data().columns))\n",
    "\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the categorical columns to numeric categories\n",
    "for col in categorical_cols:\n",
    "    merge_df[col] = pd.Categorical(merge_df[col])\n",
    "    merge_df[col] = merge_df[col].cat.codes\n",
    "    \n",
    "print(merge_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate train and test data sets from a merged dataframe\n",
    "train_1 = merge_df.iloc[0:307511,:]\n",
    "test_1 = merge_df.iloc[307511:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Train shape {} \\n Test shape {}\".format(train_1.shape, test_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create features and labesl\n",
    "train_X = train_1\n",
    "train_y = train['TARGET'].values\n",
    "test_X = test_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Print the shape of arrays\n",
    "\n",
    "print(\"Shape of training feature vector : {} \\n  Shape of training target : {} \\n Shape of test feature vector {}\".format(train_X.shape, train_y.shape, test_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Do the train, dev data split up\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train_X_1,dev_X,train_y_1,dev_y = train_test_split(train_X.values,train_y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the data into XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "ind_params = {\n",
    "   # 'seed':27,\n",
    "    'random_search_runs': 0,\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'auc',\n",
    "    #'eta': 0.001,\n",
    "    'max_leaves': 30,\n",
    "    'max_depth': 5,\n",
    "    'max_bin': 255,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'col_sample_bylevel': 1,\n",
    "    'min_child_weight': 4,\n",
    "    'lambda': 0.001,\n",
    "    'alpha': 0.001,\n",
    "   # 'scale_pos_weight': 1,\n",
    "    'early_stopping_rounds': 1000,\n",
    "    'n_estimators': 30000,\n",
    "    'objective': 'binary:logistic',\n",
    "    #'is_unbalance': True,\n",
    "    #'n_estimators': 2673,\n",
    "    #'num_leaves': 77,\n",
    "    #'learning_rate': 0.007641070180129345,\n",
    "    #'min_child_samples': 460,\n",
    "    #'boosting_type': 'gbdt',\n",
    "    #'subsample_for_bin': 240000,\n",
    "    #'reg_lambda': 0.2040816326530612,\n",
    "    #'reg_alpha': 0.8775510204081632,\n",
    "    #'subsample': 0.9494949494949496,\n",
    "    #'colsample_bytree': 0.7333333333333333,\n",
    "   #'max_depth': 5,\n",
    "   #'min_child_weight': 2,\n",
    "   #'n_estimators': 100000,\n",
    "   #'subsample': 0.7,\n",
    "   'learning_rate': 0.01,\n",
    "   #'nthread':6,\n",
    "    #'gamma':1,\n",
    "    # 'reg_alpha':0.005,\n",
    "    # 'colsample_bytree':0.8,\n",
    "    # 'scale_pos_weight':9,\n",
    "    'gpu_id':1,\n",
    "    #'reg_lambda':100.0,\n",
    "    # 'colsample_bytree':0.8,\n",
    "    'tree_method':'gpu_hist'\n",
    "    #'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    #'scale_pos_weight':200 # because training data is extremely unbalanced\n",
    "\n",
    "        }\n",
    "\n",
    "clf = xgb.XGBClassifier(**ind_params)\n",
    "model = clf.fit(train_X_1, train_y_1, eval_set=[(train_X_1, train_y_1), (dev_X, dev_y)], eval_metric='auc', early_stopping_rounds=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load the test data, predict and save the predictions\n",
    "prediction = pd.DataFrame()\n",
    "test_ids  = test.index.values\n",
    "prediction[\"SK_ID_CURR\"] = test_ids\n",
    "\n",
    "print(\"Predicting...\")\n",
    "prediction[\"TARGET\"] = model.predict_proba(data=test_X.values)[:,1]\n",
    "print(\"writing into file...\")\n",
    "prediction.to_csv(\"home_credit_submission_xgboost_2708_1.csv\",index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qPy3",
   "language": "python",
   "name": "qpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
